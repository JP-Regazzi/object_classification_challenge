{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rembg import remove\n",
    "import sys, os\n",
    "import cv2\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m output_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(input_path)\n\u001b[1;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbgcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m255\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimwrite(output_path, output)\n",
      "File \u001b[1;32mc:\\Users\\Joao Pedro\\Desktop\\Agenda-Guia\\CS\\3A\\Mention\\2025.1\\Data Challenge\\object_classification_challenge\\.venv\\lib\\site-packages\\rembg\\bg.py:266\u001b[0m, in \u001b[0;36mremove\u001b[1;34m(data, alpha_matting, alpha_matting_foreground_threshold, alpha_matting_background_threshold, alpha_matting_erode_size, session, only_mask, post_process_mask, bgcolor, force_return_bytes, *args, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m session \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    264\u001b[0m     session \u001b[38;5;241m=\u001b[39m new_session(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mu2net\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 266\u001b[0m masks \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mpredict(img, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    267\u001b[0m cutouts \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mask \u001b[38;5;129;01min\u001b[39;00m masks:\n",
      "File \u001b[1;32mc:\\Users\\Joao Pedro\\Desktop\\Agenda-Guia\\CS\\3A\\Mention\\2025.1\\Data Challenge\\object_classification_challenge\\.venv\\lib\\site-packages\\rembg\\sessions\\u2net.py:29\u001b[0m, in \u001b[0;36mU2netSession.predict\u001b[1;34m(self, img, *args, **kwargs)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, img: PILImage, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[PILImage]:\n\u001b[0;32m     18\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m    Predicts the output masks for the input image using the inner session.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;124;03m        List[PILImage]: The list of output masks.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     ort_outs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m            \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.485\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.456\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.406\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.229\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.225\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m320\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m     pred \u001b[38;5;241m=\u001b[39m ort_outs[\u001b[38;5;241m0\u001b[39m][:, \u001b[38;5;241m0\u001b[39m, :, :]\n\u001b[0;32m     38\u001b[0m     ma \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(pred)\n",
      "File \u001b[1;32mc:\\Users\\Joao Pedro\\Desktop\\Agenda-Guia\\CS\\3A\\Mention\\2025.1\\Data Challenge\\object_classification_challenge\\.venv\\lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:266\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    264\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    265\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 266\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Remove background of test images\n",
    "\n",
    "data_path = \"./data/test_image_headmind\"\n",
    "\n",
    "for i, image_name in enumerate(os.listdir(data_path)):\n",
    "    \n",
    "    if i%4 == 0:\n",
    "        print(f\"{(100*i/80):.1f}%\")\n",
    "    \n",
    "    input_path = data_path + \"/\" + image_name\n",
    "    output_path = f\"./data/preprocessed_test/{image_name}\"\n",
    "    \n",
    "    input = cv2.imread(input_path)\n",
    "    output = remove(input, bgcolor=(255, 255, 255, 255))\n",
    "    \n",
    "    cv2.imwrite(output_path, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change photo sizes to 256x256\n",
    "\n",
    "def change_image_size(input_dir, output_dir):\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Iterate through all files in the input directory\n",
    "    for file_name in os.listdir(input_dir):\n",
    "        file_path = os.path.join(input_dir, file_name)\n",
    "        \n",
    "        try:\n",
    "            # Read the image\n",
    "            img = cv2.imread(file_path)\n",
    "            if img is None:\n",
    "                print(f\"Skipping {file_name}: Not a valid image\")\n",
    "                continue\n",
    "            \n",
    "            # Get the dimensions of the original image\n",
    "            height, width = img.shape[:2]\n",
    "            \n",
    "            # Determine the size of the square\n",
    "            square_size = max(width, height)\n",
    "            \n",
    "            # Create a white square canvas\n",
    "            square_img = np.ones((square_size, square_size, 3), dtype=np.uint8) * 255\n",
    "            \n",
    "            # Calculate the position to center the original image on the canvas\n",
    "            x_offset = (square_size - width) // 2\n",
    "            y_offset = (square_size - height) // 2\n",
    "            \n",
    "            # Place the original image onto the square canvas\n",
    "            square_img[y_offset:y_offset+height, x_offset:x_offset+width] = img\n",
    "            \n",
    "            # Resize the square image to 256x256\n",
    "            resized_img = cv2.resize(square_img, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "            \n",
    "            # Save the processed image to the output directory\n",
    "            output_path = os.path.join(output_dir, file_name)\n",
    "            cv2.imwrite(output_path, resized_img)\n",
    "            \n",
    "            #print(f\"Processed and saved: {output_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to process {file_name}: {e}\")\n",
    "\n",
    "input_directory = \"./data/preprocessed_test\"\n",
    "output_directory = \"./data/preprocessed_test\"\n",
    "\n",
    "change_image_size(input_directory, output_directory)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process training images and remove background...\n",
      "i=0\n",
      "i=100\n",
      "i=200\n",
      "i=300\n",
      "i=400\n",
      "i=500\n",
      "i=600\n",
      "i=700\n",
      "i=800\n",
      "i=900\n",
      "i=1000\n",
      "i=1100\n",
      "i=1200\n",
      "i=1300\n",
      "i=1400\n",
      "i=1500\n",
      "i=1600\n",
      "i=1700\n",
      "i=1800\n",
      "i=1900\n",
      "i=2000\n",
      "i=2100\n",
      "i=2200\n",
      "i=2300\n",
      "i=2400\n",
      "i=2500\n",
      "i=2600\n",
      "i=2700\n",
      "Finished processing training images.\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../../data/DAM\"\n",
    "output_dir = \"../../data/DAM_white_background\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Blacklist explícita\n",
    "blacklist = [\n",
    "    'MONSIEUR2XWY1I.jpeg', 'MISDB1UXRH4D0.jpeg',\n",
    "    'MISDB1UXRH4C0.jpeg', 'MISDB1UXRB0O0.jpeg', 'M1710ZTEIM927.jpeg'\n",
    "]\n",
    "\n",
    "# Prefixos permitidos (exceções na blacklist para arquivos começando com 'S')\n",
    "whitelisted_prefixes = ['S204', 'S0949', 'S0918', 'S0856', 'S0204J', 'S0204OA', 'S0204OC', 'S0204OL', 'S0204OO', 'S0204P']\n",
    "\n",
    "# Remove fundo das imagens no diretório A (apenas \"M\" ou \"S\")\n",
    "print(\"Starting to process training images and remove background...\")\n",
    "\n",
    "for i, file_name in enumerate(os.listdir(data_path)):\n",
    "    if i % 100 == 0:\n",
    "        print(f\"i={i}\")\n",
    "\n",
    "    # Processa apenas arquivos que começam com \"M\" ou \"S\"\n",
    "    if file_name[0] not in {\"M\", \"S\"}:\n",
    "        continue\n",
    "\n",
    "    # Ignorar arquivos explícitos da blacklist\n",
    "    if file_name in blacklist:\n",
    "        continue\n",
    "\n",
    "    # Ignorar arquivos que começam com \"S\" mas não estão nas exceções\n",
    "    if file_name.startswith('S') and not any(file_name.startswith(prefix) for prefix in whitelisted_prefixes):\n",
    "        continue\n",
    "\n",
    "    input_path = os.path.join(data_path, file_name)\n",
    "    output_path = os.path.join(output_dir, file_name)\n",
    "\n",
    "    try:\n",
    "        # Remove o fundo preto e adiciona fundo branco\n",
    "        input_img = cv2.imread(input_path)\n",
    "        output_img = remove(input_img, bgcolor=(255, 255, 255, 255))\n",
    "\n",
    "        # Salva a imagem processada no diretório de saída\n",
    "        cv2.imwrite(output_path, output_img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_name}: {e}\")\n",
    "\n",
    "print(\"Finished processing training images.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two directories have exactly the same file names.\n"
     ]
    }
   ],
   "source": [
    "def compare_directory_filenames(dir1, dir2):\n",
    "    # Get the set of file names in each directory\n",
    "    files_dir1 = set(os.listdir(dir1))\n",
    "    files_dir2 = set(os.listdir(dir2))\n",
    "    \n",
    "    # Compare the sets\n",
    "    if files_dir1 == files_dir2:\n",
    "        print(\"The two directories have exactly the same file names.\")\n",
    "    else:\n",
    "        # Find discrepancies\n",
    "        only_in_dir1 = files_dir1 - files_dir2\n",
    "        only_in_dir2 = files_dir2 - files_dir1\n",
    "        \n",
    "        if only_in_dir1:\n",
    "            print(\"Files only in directory 1:\")\n",
    "            for file_name in sorted(only_in_dir1):\n",
    "                print(f\"  {file_name}\")\n",
    "        \n",
    "        if only_in_dir2:\n",
    "            print(\"Files only in directory 2:\")\n",
    "            for file_name in sorted(only_in_dir2):\n",
    "                print(f\"  {file_name}\")\n",
    "        \n",
    "        print(\"\\nThe directories do not have the same file names.\")\n",
    "\n",
    "# Example usage\n",
    "dir1 = \"../../data/DAM_white_background\"\n",
    "dir2 = \"../../data/DAM\"\n",
    "\n",
    "compare_directory_filenames(dir1, dir2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
